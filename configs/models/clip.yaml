# Config for training rn50x16 model using concat, concat_dot, and multiply fusion
# To switch the clip_model_type, also switch the image_processor

dataset_config:
  news_clippings:
    use_images: true
    use_features: false
    return_features_info: false
    processors:
      text_processor:
        type: clip_tokenizer
        params:
          max_seq_length: 77

model_config:
  clip: &clip
    # Choose RN101, ViT-B/32, ViT-B/16, RN50, RN50x16
    clip_model_type: ViT-B/32
    # Define parameters for the MLP classifier.
    # mlp_input_dim, mlp_hidden_dim can also be set.
    num_labels: 2
    mlp_num_layers: 2
    mlp_dropout: 0
    mlp_act: relu
    # Apply the normal lr for the classifier and
    # lr * finetune_lr_multiplier for all other layers.
    finetune_lr_multiplier: 1
    # Flags for freezing the lower or all layers
    # of CLIP but not the classifier.
    freeze_lower: False
    freeze_all: False
    # Flags for unimodal models
    image_only: False
    text_only: False
    # Flag for linear probing, same as freeze_all
    linear_probe: False
    training_head_type: classification
  clip_concat: &clip_concat
    <<: *clip
  clip_concat_dot: &clip_concat_dot
    <<: *clip
  clip_mult: &clip_mult
    <<: *clip

checkpoint:
  # Adjust the number of .ckpt files to save during training.
  max_to_keep: 1
  pretrained_state_mapping:
    model.visual: model.visual
    model.transformer: model.transformer
    model.token_embedding: model.token_embedding
    model.ln_final: model.ln_final
    model.classifier: model.classifier